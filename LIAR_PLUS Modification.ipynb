{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NUS.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQBvUzIdgdZb",
        "colab_type": "code",
        "outputId": "35d1b5ec-27bd-472d-8194-6380252b381f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7nSM2yyL2Qw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train0=pd.read_csv(\"/content/train2.tsv\", sep=\"\\t\", header=None)\n",
        "test0=pd.read_csv(\"/content/test2.tsv\", sep=\"\\t\", header=None)\n",
        "val0=pd.read_csv(\"/content/val2.tsv\", sep=\"\\t\", header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkzYGnSiMVfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train0[\"sign\"]=0\n",
        "test0[\"sign\"]=1\n",
        "val0[\"sign\"]=2\n",
        "\n",
        "df=pd.concat([train0,test0,val0]).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3Chp52TMUTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_y=df[2]\n",
        "\n",
        "del df[0]\n",
        "del df[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so2cWCkY1po-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contractions = {\n",
        "\"ain't\": \"am not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he shall\",\n",
        "\"he'll've\": \"he shall have\",\n",
        "\"he's\": \"he has\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how has\",\n",
        "\"i'd\": \"I had\",\n",
        "\"i'd've\": \"I would have\",\n",
        "\"i'll\": \"I shall\",\n",
        "\"i'll've\": \"I shall have\",\n",
        "\"i'm\": \"I am\",\n",
        "\"i've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it shall\",\n",
        "\"it'll've\": \"it shall have\",\n",
        "\"it's\": \"it has\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she shall\",\n",
        "\"she'll've\": \"she shall have\",\n",
        "\"she's\": \"she has\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that has\",\n",
        "\"there'd\": \"there had\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there has\",\n",
        "\"they'd\": \"they had\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they shall\",\n",
        "\"they'll've\": \"they shall have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what shall\",\n",
        "\"what'll've\": \"what shall have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what has\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when has\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where has\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who shall\",\n",
        "\"who'll've\": \"who shall have\",\n",
        "\"who's\": \"who has\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why has\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you shall\",\n",
        "\"you'll've\": \"you shall have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DriK79R0zusd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopword = stopwords.words(\"english\")\n",
        "\n",
        "def sord(tokens):\n",
        "    remove_sord=[word for word in tokens if word not in stopword]\n",
        "    return remove_sord\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lem(word_tokens):\n",
        "    lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in word_tokens]\n",
        "    return lemmatized_word\n",
        "\n",
        "def con(text):\n",
        "    for word in text.split():\n",
        "        if word in contractions:\n",
        "            text = text.replace(word, contractions[word.lower()])\n",
        "    return text\n",
        "\n",
        "def embed(tokens):\n",
        "    x=model[\"code\"]*0\n",
        "    n=0\n",
        "    for word in tokens:\n",
        "         if word in model.wv.vocab:\n",
        "            x=x+model[word]\n",
        "            n=n+1\n",
        "            x=x/n;\n",
        "    return x;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XiUb1U4XFI8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "b6933ce6-78b5-4d60-9755-8db9027ad0d5"
      },
      "source": [
        "col=[3,4,6,14,15]\n",
        "for i in col:\n",
        "    df[i]=df[i].astype(str).apply(lambda x: x.lower())\n",
        "    df[i]=df[i].apply(lambda x: con(x))\n",
        "    df[i]=df[i].apply(word_tokenize)\n",
        "    df[i]=df[i].apply(lambda x: sord(x))\n",
        "    df[i]=df[i].apply(lambda x: lem(x))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>sign</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2635.json</td>\n",
              "      <td>[say, annies, list, political, group, support,...</td>\n",
              "      <td>[abortion]</td>\n",
              "      <td>dwayne-bohac</td>\n",
              "      <td>[state, representative]</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[mailer]</td>\n",
              "      <td>[premise, fails, back, ., annie, 's, list, mak...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10540.json</td>\n",
              "      <td>[decline, coal, start, ?, started, natural, ga...</td>\n",
              "      <td>[energy, ,, history, ,, job-accomplishments]</td>\n",
              "      <td>scott-surovell</td>\n",
              "      <td>[state, delegate]</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[floor, speech, .]</td>\n",
              "      <td>[surovell, said, decline, coal, ``, started, n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>324.json</td>\n",
              "      <td>[hillary, clinton, agrees, john, mccain, ``, v...</td>\n",
              "      <td>[foreign-policy]</td>\n",
              "      <td>barack-obama</td>\n",
              "      <td>[president]</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>democrat</td>\n",
              "      <td>70.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>[denver]</td>\n",
              "      <td>[obama, said, would, voted, amendment, present...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1123.json</td>\n",
              "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
              "      <td>[health-care]</td>\n",
              "      <td>blog-posting</td>\n",
              "      <td>[nan]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>none</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>[news, release]</td>\n",
              "      <td>[release, may, point, mikulskis, comment, coul...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9028.json</td>\n",
              "      <td>[economic, turnaround, started, end, term, .]</td>\n",
              "      <td>[economy, ,, job]</td>\n",
              "      <td>charlie-crist</td>\n",
              "      <td>[nan]</td>\n",
              "      <td>Florida</td>\n",
              "      <td>democrat</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[interview, cnn]</td>\n",
              "      <td>[crist, said, economic, ``, turnaround, starte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            1  ... sign\n",
              "0   2635.json  ...    0\n",
              "1  10540.json  ...    0\n",
              "2    324.json  ...    0\n",
              "3   1123.json  ...    0\n",
              "4   9028.json  ...    0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyyDOE925O9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "cef61769-3302-402a-dbbb-172d3acc2640"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHEoTX646cDM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ce95e8ba-9de2-4d4c-c177-1d7855dc6cb4"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "filename = \"/content/drive/My Drive/GoogleNews-vectors-negative300 (1).bin.gz\"\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuHL9lVoJleH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "c0c9fde9-35dc-48c4-9123-822691439779"
      },
      "source": [
        "df1_3=pd.DataFrame(df[3].apply(lambda x: embed(x)).values.tolist())\n",
        "df1_15=pd.DataFrame(df[15].apply(lambda x: embed(x)).values.tolist())\n",
        "df1_4=pd.DataFrame(df[4].apply(lambda x: embed(x)).values.tolist())\n",
        "df1_6=pd.DataFrame(df[6].apply(lambda x: embed(x)).values.tolist())\n",
        "df1_14=pd.DataFrame(df[14].apply(lambda x: embed(x)).values.tolist())\n",
        "\n",
        "df1_7=pd.get_dummies(df[7])\n",
        "df1_8=pd.get_dummies(df[8])\n",
        "\n",
        "df_num=df[[9,10,11,12,13]]\n",
        "df_num.fillna(0, inplace=True)\n",
        "\n",
        "df1=pd.concat([df1_4, df1_6, df1_14, df1_7, df1_8, df1_3, df1_15, df_num], axis=1)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4034: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  downcast=downcast, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_eP8V5PQMWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1[\"sign\"]=df[\"sign\"]\n",
        "\n",
        "train=df1[df1[\"sign\"]==0]\n",
        "test=df1[df1[\"sign\"]==1]\n",
        "val=df1[df1[\"sign\"]==2]\n",
        "\n",
        "del train[\"sign\"]\n",
        "del test[\"sign\"]\n",
        "del val[\"sign\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T6ZHL63SnkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "26455a8c-9739-4836-b106-ef8bc65438c0"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gbrt1 = GradientBoostingClassifier(random_state=0,max_depth=4, learning_rate=0.1)\n",
        "gbrt1.fit(train, train_y)\n",
        "print(\"Accuracy on training set: {:.6f}\".format(gbrt1.score(train, train_y)))\n",
        "print(\"Accuracy on test set: {:.6f}\".format(gbrt1.score(test, test_y)))\n",
        "# # Model Accuracy: how often is the classifier correct?\n",
        "# print(\"Accuracy:\",metrics.accuracy_score(val_y, y))"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 0.875293\n",
            "Accuracy on test set: 0.434096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoO5LNuNlFMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_y=gbrt1.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6mwqDROlb38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tru=[\"true\", \"mostly-true\", \"half-true\"]\n",
        "fals=[\"false\", \"pants-fire\", \"barely-true\"]\n",
        "p_y=[]\n",
        "t_y=[]\n",
        "i=0\n",
        "for word in pred_y:\n",
        "    if word in tru:\n",
        "        p_y.append(\"true\")\n",
        "    else:\n",
        "        p_y.append(\"false\")\n",
        "    i=i+1\n",
        "    \n",
        "i=0\n",
        "for word in test_y:\n",
        "    if word in tru:\n",
        "        t_y.append(\"true\")\n",
        "    else:\n",
        "        t_y.append(\"false\")\n",
        "    i=i+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWjGOqpem4U8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eddc2414-3150-4eb7-a7d5-906d90b99b5e"
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(t_y, p_y))"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7158642462509865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unuq4GADmwjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "schFQ3SAhnyP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "1eeb2cf5-0bb4-4c03-cf5f-980773752709"
      },
      "source": [
        "from sklearn.svm import SVC # \"Support Vector Classifier\" \n",
        "clf = SVC(kernel='rbf') \n",
        "  \n",
        "# fitting x samples and y classes \n",
        "clf.fit(train, train_y) "
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
              "    shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVwEM2_Qjs7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_y=clf.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtGMpN_VkE4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72a167e1-ff37-446c-d69c-ad2649a61760"
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(test_y, pred_y))"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.38595106550907654\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}